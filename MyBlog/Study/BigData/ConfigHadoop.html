<!DOCTYPE html>
<html>
	<head>
		<meta charset="UTF-8">
		<title>集群环境搭建</title>
		<meta name="keywords" content="¸öÈË²©¿Í,ÑîÇà¸öÈË²©¿Í,¸öÈË²©¿ÍÄ£°å,ÑîÇà" />
		<meta name="description" content="ÑîÇà¸öÈË²©¿Í£¬ÊÇÒ»¸öÕ¾ÔÚwebÇ°¶ËÉè¼ÆÖ®Â·µÄÅ®³ÌÐòÔ±¸öÈËÍøÕ¾£¬Ìá¹©¸öÈË²©¿ÍÄ£°åÃâ·Ñ×ÊÔ´ÏÂÔØµÄ¸öÈËÔ­´´ÍøÕ¾¡£" />
		<meta name="viewport" content="width=device-width, initial-scale=1.0">
		<link href="../../css/base.css" rel="stylesheet">
		<link href="../../css/index.css" rel="stylesheet">
		<link href="../../css/m.css" rel="stylesheet">
		<link href="../../css/directory.css" rel="stylesheet">
		<link href="http://cdn.bootcss.com/highlight.js/8.0/styles/monokai_sublime.min.css" rel="stylesheet">  
		<script src="http://cdn.bootcss.com/highlight.js/8.0/highlight.min.js"></script>
		<script >hljs.initHighlightingOnLoad();</script>  
		<!--[if lt IE 9]>
<script src="js/modernizr.js"></script>
<![endif]-->
	</head>
	<body>
		<header>
  			<div class="tophead">
    				<div class="logo"><a href="iOSTable.html">赵博个人博客</a></div>
 		 	</div>
		</header>
		<article>
			<h1 class="t_nav"><a href="BigDataList.html" class="n1">目录</a></h1>
			<div class="bigDataDiv">
    				<div class="mt20"></div>
    				<li>
	      			<h2 class="blogtitle">Hadoop基础集群搭建</h2>
	      			<h3 class="blogtitle">Linux准备工作</h3>
	      			<pre><code>
//SSH免密登录
ssh-keygen -t rsa
Enter file in which to save the key (/root/.ssh/id_rsa):回车
回车
回车
#配成自己的ip
ssh-copy-id 192.168.219.12
	      			</code></pre>
	      			<hr />
	      			<h3 class="blogtitle">配置java环境</h3>
	      			<pre><code>
cd /usr/
mkdir apps
	      			</code></pre>
	      			<h4>安装java：2种方法</h4>
	      			<p>官网有.rmp与.tar.gz 2种包下哪个都行</p>
	      			<h4>安装java：第一种.rpm方法</h4>
					<img class="showPic" src="../StudyImg/BigDataImg/bigData01.png" style="width: 300px;height: 150px"/>
					<br/>
					<br/>
					<pre><code>
rpm -ivh jdk1.8.0.rpm /usr/apps
java -version	#能输出则证明安装成功	
find / -name java	#查看java路径	
vi /etc/profile		#配置路径
JAVA_HOME=/usr/java/jdk1.8.0_181-amd64
PATH=.:$PATH:$JAVA_HOME/bin
export JAVA_HOME PATH
source /etc/profile	#重启配置文件
					</code></pre>
					
					<h4>安装java：第二种.tar.gz方法</h4>
					<pre><code>
tar -zxvf jdk-x.x.x.tar.gz ~/usr/local	#解压包
#重复上面步骤，安装完后把源码包删除
rm -rf jdk-x.x.x.rmp
					</code></pre>
					<br/>
					<em class="logoTile">以上就是java环境搭建</em>
					<hr />
    				</li>
    				<li>
	      			<h3>安装hadoop</h3>
	      			<p>hadoop为集群所以最少需要3台Linux机器</p>
					<img class="showPic" src="../StudyImg/BigDataImg/bigData02.png"/ style="width: 300px;height: 150px">
					<pre><code>
tar -zxvf hadoop-3.1.1.gz -C  /usr/apps/
cd /usr/apps/hadoop-3.1.1/share
rm -rf doc/
					</code></pre>
					<h4>配置hadoop环境</h4>
					<p>3.0以后需要配置6个文件</p>
					<p> 
						hadoop-3.0.0/etc/hadoop/hadoop-env.sh <br />
        					hadoop-3.0.0/etc/hadoop/yarn-env.sh  <br />
        					hadoop-3.0.0/etc/hadoop/core-site.xml <br /> 
       					hadoop-3.0.0/etc/hadoop/hdfs-site.xml  <br />
        					hadoop-3.0.0/etc/hadoop/mapred-site.xml <br />
       				    hadoop-3.0.0/etc/hadoop/yarn-site.xml
					</p>
					<h5>1.配置hadoop-env.sh</h5>
					<pre><code>
#The java implementation to use ...	
export JAVA_HOME=/usr/java/jdk1.8.0_181-amd64				
					</code></pre>

					<h5>2.配置core-site.xml</h5>
					<pre><code>
&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;fs.defaultFS&lt;/name&gt;
		&lt;value&gt;hdfs://192.168.219.11:9000/&lt;/value&gt;
	&lt;/property&gt;
&lt;/configuration&gt;
					</code></pre>
					<h5>3.配置hdfs-site.xml</h5>
					<pre><code>
&lt;!—其他的机器不需要配置第一个property块--&gt;</span>
&lt;configuration&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;
		&lt;value&gt;/root/hdpdata/name&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
		&lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;
		&lt;value&gt;/root/hdpdata/data&lt;/value&gt;
	&lt;/property&gt;
	&lt;property&gt;
        	&lt;name&gt;dfs.namenode.secondary.http-address&lt;/name&gt;
        	&lt;value&gt;192.168.219.12:9870&lt;/value&gt;
    	&lt;/property>
&lt;/configuration&gt;
					</code></pre>
					<br />
					<h5>3.配置hadoop路径</h5>
					<pre><code>
vi /etc/profile
JAVA_HOME=/usr/java/jdk1.8.0_181-amd64
export HADOOP_HOME=/usr/apps/hadoop-3.1.1
PATH=.:$PATH:$JAVA_HOME/bin:$HADOOP_HOME/bin:$HADOOP_HOME/sbin
export JAVA_HOME  PATH
#保存退出
#发给其他台
scp -r hadoop3.1.1/192.168.219.12 /usr/apps/
					</code></pre>
					<h4>启动hadoop</h4>
						<br />
						<h5>启动hadoop3.0+</h5>
						<pre><code>
hadoop namenode -format	#第一台机器（namenode）初始化
hdfs --daemon start namenode	#第一台机器
hdfs --daemon start datanode	#所有机器
						</code></pre>
						<h5>启动hadoop2.0+</h5>
						<pre><code>
hadoop namenode -format
bash hadoop-daemon.sh start namenode
bash hadoop-daemon.sh start datanode							
						</code></pre>
						<br/>
						<pre><code>
jps	#查看进程
netstat -nltp | grep 1469	#1469就是Namenode进程号
						</code></pre>
						<p>谷歌浏览器输入ip:端口进入hadoop本地环境网站查看</p>
						<hr />
						<h5>配置一键启动2.0+(3.0+不知道好使不好使)</h5>
						<p>namenode配置所有机器免密登录</p>
						<p>进入hadoop对应文件夹下/etc/hadoop</p>
						<p>vi slaves  <span class="annotation">#填写所有机器的ip地址</span></p>
						<p>start -dfs.sh <span class="annotation">#开启</span></p>
						<p>stop -dfs.sh<span class="annotation">#关闭</span></p>
						<hr />
						<p>bash start-all.sh <span class="annotation">启动五大进程</span></p>
						<br/>
						<br/>
						<br/>
						<p>有的时候会有问题导致版本id对应不上效果如下datanode无法启动
						解决如下：
							查看问题为 hadoop文件夹里logs日志中
							 dfs.datanode.data.dir在本地系统的路径下的current/VERSION中的clusterID改为与namenode一样。重启即可！ 
							 重新加载配置文件resource hdfs-site.xml
						</p>

    				</li>
    			</div>
		</article>
		
	</body>
</html>
